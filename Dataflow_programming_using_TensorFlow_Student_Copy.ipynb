{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataflow programming using TensorFlow Student  Copy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samialabed/r244_dataflow_tutorial/blob/main/Dataflow_programming_using_TensorFlow_Student_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ko6NuYl1es"
      },
      "source": [
        "# Dataflow programming using TensorFlow \n",
        "\n",
        "\n",
        "## Introduction\n",
        "The goal of this tutorial is to understand how dataflow programming can be used to construct computational graphs, and how these graphs can be executed using distributed workers and parameter servers.\n",
        "\n",
        "This tutorial is structured as follow: first we will use a high-level TensorFlow API which hides a lot of the data flow programming complexity, the goal here is to get familiar with TF and understand what is the expectation from end-user perspective, then we will unpack the abstraction layers one by one, looking at what TF is doing behind the scene and then attempt to run this in a distributed fashion.\n",
        "\n",
        "\n",
        "The final exercise on data structures in computation graphs is meant for students with substantial prior experience. There is no expectation to complete all exercises, and if you are entirely new to TensorFlow, you should prioritize understanding the first exercises well.\n",
        "\n",
        "\n",
        "### Extra help:\n",
        "* [TensorFlow v1.x Tutorials](https://github.com/tensorflow/docs/tree/master/site/en/r1/tutorials)\n",
        "* [Distributed TensorFlow V1.5 Tutorial](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md)\n",
        "* [TensorFlow v1.15 API Docs](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf)\n",
        "\n",
        "#### What is this \"Colab\" environment: \n",
        "  * You can think of it as a collaborative Jupyter notebook, you can write and execute Python code on the cloud without any setup required and provide a real-time sharing/pair programming capabilities. It comes preloaded with most of the popular data science and machine learning libraries.\n",
        "  * If you need to install extra packages (outside the scope of this tutorial) you can do so by executing a cell with this command `!pip install <name of package>`  \n",
        "  * [Introductionary video on Colab](https://www.youtube.com/watch?v=inN8seMm7UI)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMtam8ghU1U"
      },
      "source": [
        "# Setup and loading packages\n",
        "The next cell imports all the needed libraries for this exercise as well as loads the correct version of TensorFlow (v1.15) and not the new TensorFlow (v2.3).\n",
        "\n",
        "This tutorial is meant to demonstrate the construction of *static* computational graphs whereby a computation is first designed by connection graph fragments, and later execution by explicitly invoking this graph.\n",
        "This is in contrast to an imperative ('eager'/'define-by-run' execution) where the code is executed directly like any other Python code. Eager TensorFlow relies on various utilities to transform the executed code to a static graph (for purposes of deployment and optimization). The goal of the exercise is hence to understand how static and eager implementations correspond. Eager execution is default in TensorFlow >= 2.0.\n",
        "We will explore eager execution at the end of this tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ABGAtKAnqU0"
      },
      "source": [
        "#@title Execute this cell! \n",
        "# We will be using TF v1.5 in this tutorial \n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "\n",
        "# import package as normal, TF is installed by default \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorboard\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Clear any tensorboard logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "# Define the TensorBoard settings, will be explained later.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/func/%s' % stamp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjphLBZzhyWY"
      },
      "source": [
        "#@title Hello TensorFlow: Example executing TFv1.15 on Colab\n",
        "\n",
        "\n",
        "# check python version is indeed 1.x\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "\n",
        "# taking parameter input as widget - feel free to change on the right side.\n",
        "scaler_input = 5 #@param {type:\"number\"}\n",
        "# executing simple matrix multipication using TF\n",
        "ones_vector = tf.ones(shape=(3,))\n",
        "# Create a TF session to execute the TF graph.\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "print(sess.run(ones_vector * scaler_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N-XxFa7dy-o"
      },
      "source": [
        "# Linear regression using TensorFlow\n",
        "\n",
        "In this task, you will learn about placeholders, Tensor variables and constants in the TensorFlow graph. You will implement a simple linear regression and optimise its weights using TensorFlow's gradient descent optimiser. A machine learning task in TensorFlow typically means to create a loss function on the output of the graph, and then let TensorFlow update the weights in the graph via any gradient based optimisation method (such as stochastic gradient descent). This is possible because TensorFlow has registered gradients for most of its operators and can hence automatically compute gradients of most functions you maye define via [reverse-mode auto differentation.](https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BDU2AJJf_30"
      },
      "source": [
        "#@title Linear regression: Generate data points\n",
        "\n",
        "\n",
        "# Often in ML you create a fake data generator to test your model, \n",
        "# the data generator simplify the process of creating training data.\n",
        "# Here we create a simple sine function with added noises. \n",
        "\n",
        "# Generate samples of a function we are trying to predict:\n",
        "samples = 100 #@param {'type': 'number'}\n",
        "\n",
        "# Fit a line from the x-axis -5 to +5\n",
        "training_X = np.linspace(-5, 5, samples)\n",
        "training_Y = np.sin(training_X) + np.random.uniform(-0.5, 0.5, samples)\n",
        "\n",
        "\n",
        "print(f'training_X.shape={training_X.shape}, trianing_Y.shape={training_Y.shape}')\n",
        "\n",
        "\n",
        "# plot the generator function \n",
        "sns.lineplot(x=training_X, y=training_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpGsYbnKRbx8"
      },
      "source": [
        "# @title Linear regression: Creating the model\n",
        "# @markdown Make sure to complete all todos here: \n",
        "\n",
        "\n",
        "\n",
        "# Reset the TF graph session to \"forget\" the previously defined model.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# First, create TensorFlow placeholders for input data (xs) and\n",
        "# output (ys) data. Placeholders are inputs to the computation graph.\n",
        "# When we run the graph, we need to feed values for the placerholders into the graph.\n",
        "\n",
        "# TODO: create placeholders for inputs and outputs\n",
        "X = #TODO\n",
        "Y = #TODO\n",
        "\n",
        "\n",
        "# We will try minimzing the mean squared error between our predictions and the\n",
        "# output. Our predictions will take the form X*W + b, where X is input data,\n",
        "# W are ou weights, and b is a bias term:\n",
        "# minimize ||(X*w + b) - y||^2\n",
        "# To do so, you will need to create some variables for W and b. Variables\n",
        "# need to be initialised; often a normal distribution is used for this.\n",
        "\n",
        "\n",
        "# TODO create weight and bias variables\n",
        "W =#TODO\n",
        "b = #TODO\n",
        "# Next, you need to create a node in the graph combining the variables to predict\n",
        "# the output: Y = X * w + b. Find the appropriate TensorFlow operations to do so.\n",
        "\n",
        "# TODO: Create the prediction variable\n",
        "predictions = #TODO\n",
        "\n",
        "# Finally, we need to define a loss that can be minimized using gradient descent:\n",
        "# The loss should be the mean squared difference between predictions and outputs.\n",
        "\n",
        "# TODO: Create loss\n",
        "loss_function =#TODO\n",
        "\n",
        "\n",
        "# Add tensorboard visualisation \n",
        "writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idEFFU5GUde0"
      },
      "source": [
        "#@title Linear regression: Optimisation loop\n",
        "\n",
        "# Use gradient descent to optimise your variables\n",
        "\n",
        "# Feel free to play with the optimisation loop \n",
        "learning_rate = 0.001 #@param {'type':'number'}\n",
        "# Maybe experiment using other optimisers such as Adam\n",
        "optimizer = tf.compat.v1.train.GradientDescentOptimizer (learning_rate).minimize(loss_function)\n",
        "\n",
        "# We create a session to use the graph and initialize all variables\n",
        "session = tf.compat.v1.Session()\n",
        "session.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "# Optimisation loop\n",
        "epochs = 1000 #@param {'type':'number'} \n",
        "\n",
        "previous_loss = 0.0\n",
        "for epoch in range(epochs):\n",
        "    #TODO run the optimize op: look up \"feed_dict\" in session.run api docs\n",
        "    _, loss = # TODO run session for optimizer and loss\n",
        "\n",
        "    if epoch % 10 = 0:\n",
        "      print(f'Epoch: {epoch}, Loss = {loss}')\n",
        "    # Termination condition for the optimization loop\n",
        "    if np.abs(previous_loss - loss) < 0.000001:\n",
        "        break\n",
        "    previous_loss = loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaSuNjDzYCMU"
      },
      "source": [
        "#@title Visualisation \n",
        "\n",
        "# TODO try plotting the predictions by using the model to predict outputs,\n",
        "#TODO, run the prediction operation\n",
        "model_predictions = # TODO\n",
        "#TODO Plot using plt.plot both the prediction and compare against the real function\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_QYr1KAWg1E"
      },
      "source": [
        "# (non)-Linear regression part 2\n",
        "Try to understand what the program above did. \n",
        "How well did your function fit the data?\n",
        "\n",
        "In the task so far, you tried to fit a linear model (single line) to a non-linear function (the sine-function) using a gradient based optimisation. \n",
        "Try to now expanding your model to be able to fit non-linear functions, effectively turning it into a neural network. You can do this by either manually adding weights, layers and activations or using TensorFlow's existing layer API. \n",
        "\n",
        "While at it, it is helpful to visualise what TensorFlow is doing behind the scene, for that we will explore TensorBoard - a debugging tool that let you visualise the data flow programming model of TF.\n",
        "\n",
        "If you look at the first cell in Colab you will see we have already imported tensorboard and invoked its plugin using `%load_ext tensorboard`. If you are doing this exercise locally, you will want to read on [TensorBoard doc](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graph_viz.md) how to set it up locally.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmlbREb6Xvwo"
      },
      "source": [
        "#@title starting tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgIseRPyjk0M"
      },
      "source": [
        "## Tensorboard\n",
        "\n",
        "Examine the Tensorboard, try to pinpoint how each variable and placeholder you defined is structured in the graph.\n",
        "\n",
        "To understand the nodes representation give the [Tensorboard Docs](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/graph_viz.md) a read.\n",
        "\n",
        "\n",
        "### Tensorboard exercise\n",
        "\n",
        "Answer these questions and attach it in your submission:\n",
        "* What happens when you declare a TensorFlow variables and assign it random weights? \n",
        "* Can you identify points that are not sequentially dependent on each other as oppurtinity for parallelisation? \n",
        "* Explore the loss function (you can expand nodes in Tensorboard graph) and try to describe what is happening there.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6y2tsJkmcGM"
      },
      "source": [
        "# Non-linear regression in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIrBgy_Yj7FM"
      },
      "source": [
        "#@title Making the Linear regression non-linear\n",
        "\n",
        "# Reset the TF graph session to \"forget\" the previously defined model.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "hidden_units = 64 #@param{'type': 'number'}\n",
        "number_of_layers = 2 #@param{'type': 'number'}\n",
        "learning_rate = 0.0001 #@param{'type': 'number'}\n",
        "\n",
        "# Create the model \n",
        "model =  tf.keras.Sequential()\n",
        "#TODO add layers to the model.\n",
        "\n",
        "# Add tensorboard visualisation \n",
        "writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())\n",
        "# Display the model\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJoFVZtxmd8o"
      },
      "source": [
        "epochs = 1000 #@param {'type':'number'}\n",
        "#TODO fit the model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehOiAV56moa8"
      },
      "source": [
        "#@title Visualisation \n",
        "\n",
        "#@markdown TODO, run the prediction operation for the model and plot prediction against real function \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjXqVTsitCDo"
      },
      "source": [
        "## Non-linear regression: More ML\n",
        "\n",
        "Observe what you have just done. Did your model fit the data perfectly? did it overfit the data? Try giving your model less data and see how well it fit the data, try 70/30 train/test split and test.\n",
        "If your model is not generalising (performing well) on your test data, maybe you should explore using regularisation techniques or maybe increase training epochs.\n",
        "\n",
        "Maybe consider adding another term to the generator function, how well your model will generalise? \n",
        "Is your model too complex and now you have too many parameters? consider optimisation using Bayesian optimisation (check the advanced section).\n",
        "\n",
        "If you have reached it so far without any prior TensorFlow experience, well done! it is very confusing at the beginning with many terminologies thrown around. Feel freee to ask for any additional materials if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tUWMgvVlslQ"
      },
      "source": [
        "# Distributed TensorFlow\n",
        "\n",
        "After completion of the linear regression exercise, you should have a basic intuition of how to create and run dataflow graphs. In the following exercise, you will expand upon this by running distributed TensorFlow.\n",
        "\n",
        "When using distributed TensorFlow to run large computation graphs in clusters, you have to create a training server and communicate with it:\n",
        "``` python\n",
        "import tensorflow as tf\n",
        "c = tf.constant(\"Hello, distributed TensorFlow!\")\n",
        "server = tf.train.Server.create_local_server()\n",
        "sess = tf.Session(server.target)  # Create a session on the server.\n",
        "sess.run(c)\n",
        "'Hello, distributed TensorFlow!'\n",
        "```\n",
        "\n",
        "While the intricacies of the different distributed training modes are beyond the scope of this tutorial, you may want to read the first sections of the [tutorial](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md).\n",
        "\n",
        "The purpose of distributed TensorFlow is to have fine-grained control over which part of your computation is executed on which device. For example, when training large machine learning models, you may typically want to use your CPU to read and preprocess training data and your GPU to compute updates on the model. In the next task, you will distribute a simple computation and learn about device scopes and cluster specifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy934MzJl8ks"
      },
      "source": [
        "import tensorflow as tf\n",
        "c = tf.constant(\"Hello, distributed TensorFlow!\")\n",
        "server = tf.train.Server.create_local_server()\n",
        "sess = tf.Session(server.target)  # Create a session on the server.\n",
        "sess.run(c)\n",
        "'Hello, distributed TensorFlow!'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tc8D5GkkoP0"
      },
      "source": [
        "# Distributed MapReduce\n",
        "\n",
        "MapReduce is a parallel programming model wherein a task is split to multiple workers performing map() operations on the input (such as filtering or sorting data), and another task running a reduce() operation to aggregate the results. A typical example for this would be filtering Tweets for certain hashtags in realtime as a map() task, and a reduce() task to sum up and present the result statistics (image source: Wikipedia):\n",
        "![](https://www.cl.cam.ac.uk/research/srg/netos/projects/cambridgeplus/2020/640px-Mapreduce_Overview.svg.png)\n",
        "\n",
        "\n",
        "The goal of your task is to distribute a computation implementing the MapReduce paradigm in distributed TensorFlow. First, you will familiarise yourself with cluster specifications. The principal idea behind running a TensorFlow cluster is to create a cluster specification describing jobs and devices, then initialising a server with this spec:\n",
        "\n",
        "```python\n",
        "cluster_spec = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})\n",
        "server = tf.train.Server(cluster_spec, job_name=\"local\", task_index=task)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Because Colab environment is actually a virtual machine running on Google servers, it is not trivial to run multiple threads. For that we will use two tricks to get around it.\n",
        "\n",
        "First, you will need to download the \"server\" file\n",
        "\n",
        "The code inside the server is very simple:\n",
        "```python\n",
        "import tensorflow.compat.v1 as tf\n",
        "import sys\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "    # Parse command <name of the task>\n",
        "    task = int(argv[1])\n",
        "\n",
        "    # allow only two tasks, either 0 or 1,\n",
        "\n",
        "    # task 0 maps to port 2222, task 1 maps to port 2223\n",
        "    cluster_spec = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})\n",
        "    server = tf.train.Server(cluster_spec, job_name=\"local\", task_index=task)\n",
        "\n",
        "    print(\"Initialising server {}\".format(task))\n",
        "    server.start()\n",
        "\n",
        "    # This server will now wait for instructions - n.b. that we did not\n",
        "    # define an interrupt signal, so you have to close the terminal to kill it\n",
        "    server.join()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv)\n",
        "```\n",
        "\n",
        "\n",
        "Once the file is downloaded in your colab, we will execute it using a colab magic\n",
        "`%%bash --bg` means runs bash command in the background.\n",
        "So we will start two separate \"workers\" waiting for tasks from a manager. The next two cells just do that.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea6mVOJ371WM"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/samialabed/r244-large-scale-systems/master/server_init.py\"\n",
        "\n",
        "# Download the server file. Feel free to inspect it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f735bZET5YHs"
      },
      "source": [
        "%%bash --bg\n",
        "\n",
        "python server_init.py 0\n",
        "\n",
        "# run a worker on a background thread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbd4cqM_5fFA"
      },
      "source": [
        "%%bash --bg\n",
        "\n",
        "python server_init.py 1\n",
        "# run a second worker on a separate thread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5GB0tRvmJnE"
      },
      "source": [
        "cluster_spec = tf.train.ClusterSpec({\"local\": [\"localhost:2222\", \"localhost:2223\"]})\n",
        "task_input = tf.placeholder(tf.float32, 100)\n",
        "\n",
        "# First part: compute mean of half of the input data\n",
        "with tf.device(\"/job:local/task:0\"):\n",
        "    local_input_task0 = tf.slice(task_input, [50], [-1])\n",
        "    local_mean_task0 = tf.reduce_mean(local_input_task0)\n",
        "\n",
        "# TODO do another half of the computation using another device\n",
        "with # TODO: \n",
        "    pass \n",
        "\n",
        "# TODO compute the overall result by combining both results\n",
        "global_mean = # TODO\n",
        "\n",
        "# TODO Fill in the session specification\n",
        "with TODO as sess:\n",
        "    # Sample some data for the computation\n",
        "    data = np.random.random(100)\n",
        "\n",
        "    # and the input data. Output the result.\n",
        "    mean = sess.run(global_mean, feed_dict={task_input: data})\n",
        "    print(mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTx9h2Cdn7DI"
      },
      "source": [
        "# Advance tutorial\n",
        "\n",
        "If you have managed to complete the whole tutorial and still feeling you want to do more:\n",
        "\n",
        "## Investigate the \"new\" Eager execution API:\n",
        "The old TF API (V1.x) used to have explicit data flow programming, which many data scientists and machine learning practioners found difficult to use.\n",
        "However, Data flow programming is an important computing paradigm, it allows you to provide better runtime optimisations for programmes and easier handling of multi-processor. \n",
        "\n",
        "You can set the tensorflow version in Colab by executing this command in its own cell: ` %tensorflow_version 1.x` or `%tensorflow_version 2.x`\n",
        "\n",
        "Start a new cell with `%tesnroflow_version 2.x` and try to redo the whole tutorial including distributed training and tensorboard.\n",
        "* [TensorFlow V2.x tutorials](https://www.tensorflow.org/tutorials)\n",
        "\n",
        "\n",
        "* **Distributed training in V2**: There is a very good documentation on how to do [distributed training on Colab](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/distributed_training.ipynb)\n",
        "\n",
        "\n",
        "## End-to-end computation graphs\n",
        "\n",
        "In the first exercise, you used Python code to create TensorFlow computations. You then repeatedely invoked a TensorFlow session to perform training. Each session call results in a context switch between your Python program and the TensorFlow runtime. A more sophisticated implementation would include the loop as part of a computation graph so only a single call to TensorFlow is necessary. Look at the TensorFlow control flow operations (e.g. a while loop.) and try modifying your code so all control-flow is in-graph. \n",
        "\n",
        "\n",
        "## Advanced exercise: data structures in computation graphs\n",
        "\n",
        "In the prior exercises, you implemented largely functional transformations using different graph paradigms. The computation required you to send input data through a graph, and the optimizer updated internal state automatically (network weights). In some subfields of machine learning like reinforcement learning (RL), algorithms must manage substantial amounts of state. For example, an RL algorithm often needs to write data to a buffer, and later needs to sample from that buffer. Implementing stateful data structures in TensorFlow can be difficult because there are restrictions on variable manipulation and control flow. In this exercise, you will implement a priority queue in pure session-based TensorFlow.\n",
        "\n",
        "The priority queue should enable users to insert simple data (e.g. a single integer) with an associated priority. The priority queue has a limited size n (e.g. 10), so you need to think about how priority is maintained when elements are inserted and removed if the queue is full. Further, the priority queue must support a dequeue operation which lets users read any number (< n) of records from the queue, ordered by priority. Hint: Think about how data and priorities may be managed separately. \n",
        "\n",
        "## Tune the network parameters with Bayesian optimisation\n",
        "Machine learning in general has many parameters that govern the speed of convergance (or even convergance in the first place) and the quality of the resulting network.\n",
        "Choosing these parameters is a difficult task, there are several methods for choosing these parameters: random search, grid search, and Bayesian optimisation.\n",
        "\n",
        "In this course you will come across Bayesian optimisation (BO) in many different papers, as it is a framework that has found applicability in many different fields.\n",
        "BO attempt to find set of parameters that minimises an objective function.\n",
        "This can be the RSE \n"
      ]
    }
  ]
}